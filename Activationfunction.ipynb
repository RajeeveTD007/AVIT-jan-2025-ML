{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g67_960H7f8",
        "outputId": "9659c260-7aa7-429f-e5d8-3f55ca9cbc5e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 82ms/step - accuracy: 0.3414 - loss: 1.8036 - val_accuracy: 0.5372 - val_loss: 1.2972\n",
            "Epoch 2/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 85ms/step - accuracy: 0.5616 - loss: 1.2451 - val_accuracy: 0.5970 - val_loss: 1.1371\n",
            "Epoch 3/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 81ms/step - accuracy: 0.6195 - loss: 1.0895 - val_accuracy: 0.6376 - val_loss: 1.0515\n",
            "Epoch 4/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 80ms/step - accuracy: 0.6547 - loss: 0.9911 - val_accuracy: 0.6176 - val_loss: 1.1024\n",
            "Epoch 5/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 81ms/step - accuracy: 0.6710 - loss: 0.9402 - val_accuracy: 0.6750 - val_loss: 0.9468\n",
            "Epoch 1/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m613s\u001b[0m 869ms/step - accuracy: 0.4342 - loss: 1.6289 - val_accuracy: 0.5650 - val_loss: 1.2383\n",
            "Epoch 2/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m619s\u001b[0m 865ms/step - accuracy: 0.5694 - loss: 1.2388 - val_accuracy: 0.5826 - val_loss: 1.1926\n",
            "Epoch 3/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 864ms/step - accuracy: 0.5914 - loss: 1.1724 - val_accuracy: 0.5966 - val_loss: 1.1546\n",
            "Epoch 4/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 872ms/step - accuracy: 0.6058 - loss: 1.1273 - val_accuracy: 0.5980 - val_loss: 1.1569\n",
            "Epoch 5/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m622s\u001b[0m 873ms/step - accuracy: 0.6148 - loss: 1.0977 - val_accuracy: 0.6024 - val_loss: 1.1400\n"
          ]
        }
      ],
      "source": [
        "#write a simple python program to Build an ensemble model to classify images\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the image data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define a simple CNN model\n",
        "def build_cnn_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define a model using a pretrained base (VGG16)\n",
        "def build_pretrained_model():\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Build base models\n",
        "cnn_model = build_cnn_model()\n",
        "pretrained_model = build_pretrained_model()\n",
        "\n",
        "# Compile the base models\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "pretrained_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train base models\n",
        "cnn_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "pretrained_model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Ensemble model: average predictions from both models\n",
        "class EnsembleModel(tf.keras.Model):\n",
        "    def __init__(self, models):\n",
        "        super(EnsembleModel, self).__init__()\n",
        "        self.models = models\n",
        "\n",
        "    def call(self, inputs):\n",
        "        predictions = [model(inputs) for model in self.models]\n",
        "        return tf.reduce_mean(predictions, axis=0)\n",
        "\n",
        "# Create an ensemble model\n",
        "ensemble_model = EnsembleModel([cnn_model, pretrained_model])\n",
        "\n",
        "# Evaluate the ensemble model on test data\n",
        "ensemble_predictions = ensemble_model(x_test)\n",
        "ensemble_accuracy = tf.keras.metrics.categorical_accuracy(y_test, ensemble_predictions)\n",
        "print(f\"Ensemble Accuracy: {tf.reduce_mean(ensemble_accuracy).numpy():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55uJKqvUIeOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xAx7sjuVIeZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}