{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPeNmIjOYidCyFcy3Q9OCan"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"y9_1X6LkWJlu"},"outputs":[],"source":["### Predicting Sales Revenue for a Retail Store\n","\n","# Step 1: Data Pre-processing\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","\n","# Load dataset\n","data = pd.read_csv('retail_sales.csv')  # Replace with actual dataset file\n","\n","# Display initial dataset information\n","print(\"Dataset Head:\")\n","print(data.head())\n","print(\"\\nDataset Info:\")\n","print(data.info())\n","\n","# Handle missing values\n","imputer = SimpleImputer(strategy='mean')\n","data['sales'] = imputer.fit_transform(data[['sales']])\n","\n","# Separate features and target\n","X = data.drop('sales', axis=1)\n","y = data['sales']\n","\n","# Categorical and numerical columns\n","categorical_cols = X.select_dtypes(include=['object']).columns\n","numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n","\n","# Preprocessing pipeline\n","categorical_transformer = Pipeline(steps=[\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])\n","\n","numerical_transformer = Pipeline(steps=[\n","    ('scaler', StandardScaler())\n","])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_cols),\n","        ('cat', categorical_transformer, categorical_cols)\n","    ])\n","\n","# Final preprocessed dataset\n","X = preprocessor.fit_transform(X)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 2: Feature Engineering\n","from sklearn.feature_selection import SelectKBest, f_regression\n","\n","# Select top 10 features\n","selector = SelectKBest(score_func=f_regression, k=10)\n","X_train = selector.fit_transform(X_train, y_train)\n","X_test = selector.transform(X_test)\n","\n","# Step 3: Model Building\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.neural_network import MLPRegressor\n","\n","models = {\n","    'Linear Regression': LinearRegression(),\n","    'Random Forest': RandomForestRegressor(random_state=42),\n","    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n","    'Artificial Neural Network': MLPRegressor(random_state=42, max_iter=500)\n","}\n","\n","# Train models\n","trained_models = {}\n","for name, model in models.items():\n","    model.fit(X_train, y_train)\n","    trained_models[name] = model\n","\n","# Step 4: Evaluation\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","results = []\n","for name, model in trained_models.items():\n","    y_pred = model.predict(X_test)\n","    mse = mean_squared_error(y_test, y_pred)\n","    mae = mean_absolute_error(y_test, y_pred)\n","    r2 = r2_score(y_test, y_pred)\n","    results.append({\n","        'Model': name,\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2\n","    })\n","\n","# Display results\n","results_df = pd.DataFrame(results)\n","print(\"\\nModel Comparison:\")\n","print(results_df.sort_values(by='R2', ascending=False))\n","\n","# Conclusion and Best Model\n","best_model = results_df.sort_values(by='R2', ascending=False).iloc[0]\n","print(f\"\\nBest Model: {best_model['Model']} with R2 Score: {best_model['R2']:.2f}\")\n","\n","# Save the best model\n","import joblib\n","joblib.dump(trained_models[best_model['Model']], 'best_model.pkl')\n","\n","# Summary and Future Steps\n","\"\"\"\n","This notebook illustrates a complete workflow for predicting retail store sales. Future improvements could include:\n","1. Hyperparameter tuning for optimal performance.\n","2. Incorporating time-series data if available.\n","3. Exploring additional ensemble methods for better accuracy.\n","\"\"\"\n"]}]}